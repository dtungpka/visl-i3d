mode: "train"
experiment_name: "rgb_action_recognition"
save_checkpoints: true
log_freq: 1
plot_stats: true

dataset:
  name: "video_dataset"  # Replace with your actual RGB dataset name
  height: 224
  width: 224
  n_frames: 32          # Number of frames per video clip
  batch_size: 8         # Smaller batch size for RGB data due to memory requirements
  num_classes: 10       # Number of action classes
  output: "rgb"         # Specify RGB output instead of skeleton
  cache_folder: "/path/to/cache_folder/"
  num_workers: 4
  paths:
    train_data_path: "/path/to/train_videos/"
    val_data_path: "/path/to/val_videos/"
    test_data_path: "/path/to/test_videos/"
  augmentation:
    use_augmentation: true
    augmentations:
      temporal:
        temporal_crop_scale: [0.8, 1.0]
        random_frame_skip: true
      spatial:
        random_crop: true
        random_horizontal_flip: true
        color_jitter:
          brightness: 0.4
          contrast: 0.4
          saturation: 0.4

model:
  model_name: "simple_rgb_model"  # This must match the name registered with ModelRegistry
  in_channels: 3                 # RGB has 3 channels
  num_classes: 10
  dropout: 0.5

hyperparameters:
  optimizer: adam
  learning_rate: 0.0001
  weight_decay: 0.0001
  num_epochs: 50
  batch_size: 8
  dropout_rate: 0.5
  loss: cross_entropy

device: "cuda"  # Use "cuda" for GPU, "cpu" for CPU